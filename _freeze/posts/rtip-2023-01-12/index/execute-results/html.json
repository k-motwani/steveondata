{
  "hash": "4a782a6a6eee025048358d2613ebdb69",
  "result": {
    "markdown": "---\ntitle: \"An Update on {tidyAML}\"\nauthor: \"Steven P. Sanderson II, MPH\"\ndate: \"2023-01-12\"\ncategories: [code, rtip, tidyaml, automl]\n---\n\n\n# Introduction\n\nI have been doing a lot of work on a new package called [`{tidyAML}`](https://www.spsanderson.com/tidyAML/).  `{tidyAML}` is a new R package that makes it easy to use the `{tidymodels}` ecosystem to perform automated machine learning (AutoML). This package provides a simple and intuitive interface that allows users to quickly generate machine learning models without worrying about the underlying details. It also includes a safety mechanism that ensures that the package will fail gracefully if any required extension packages are not installed on the user’s machine. With `{tidyAML}`, users can easily build high-quality machine learning models in just a few lines of code. Whether you are a beginner or an experienced machine learning practitioner, `{tidyAML}` has something to offer.\n\nSome ideas are that we should be able to generate regression models on the fly without having to actually go through the process of building the specification, especially if it is a non-tuning model, meaning we are not planing on tuning hyper-parameters like penalty and cost.\n\nThe idea is not to re-write the excellent work the `{tidymodels}` team has done (because it’s not possible) but rather to try and make an enhanced easy to use set of functions that do what they say and can generate many models and predictions at once.\n\nThis is similar to the great `{h2o}` package, but, `{tidyAML}` does not require `java` to be setup properly like `{h2o}` because `{tidyAML}` is built on `{tidymodels}`.\n\nThis package is not yet release, so you can only install from _GitHub_ with the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"devtools\")\ndevtools::install_github(\"spsanderson/tidyAML\")\n```\n:::\n\n\n# Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyAML)\n\nfast_regression_parsnip_spec_tbl(.parsnip_fns = \"linear_reg\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 × 5\n   .model_id .parsnip_engine .parsnip_mode .parsnip_fns model_spec\n       <int> <chr>           <chr>         <chr>        <list>    \n 1         1 lm              regression    linear_reg   <spec[+]> \n 2         2 brulee          regression    linear_reg   <spec[+]> \n 3         3 gee             regression    linear_reg   <spec[+]> \n 4         4 glm             regression    linear_reg   <spec[+]> \n 5         5 glmer           regression    linear_reg   <spec[+]> \n 6         6 glmnet          regression    linear_reg   <spec[+]> \n 7         7 gls             regression    linear_reg   <spec[+]> \n 8         8 lme             regression    linear_reg   <spec[+]> \n 9         9 lmer            regression    linear_reg   <spec[+]> \n10        10 stan            regression    linear_reg   <spec[+]> \n11        11 stan_glmer      regression    linear_reg   <spec[+]> \n```\n:::\n\n```{.r .cell-code}\nfast_regression_parsnip_spec_tbl(.parsnip_eng = c(\"lm\",\"glm\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 5\n  .model_id .parsnip_engine .parsnip_mode .parsnip_fns model_spec\n      <int> <chr>           <chr>         <chr>        <list>    \n1         1 lm              regression    linear_reg   <spec[+]> \n2         2 glm             regression    linear_reg   <spec[+]> \n3         3 glm             regression    poisson_reg  <spec[+]> \n```\n:::\n\n```{.r .cell-code}\nfast_regression_parsnip_spec_tbl(.parsnip_eng = c(\"lm\",\"glm\",\"gee\"), \n                                 .parsnip_fns = \"linear_reg\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 5\n  .model_id .parsnip_engine .parsnip_mode .parsnip_fns model_spec\n      <int> <chr>           <chr>         <chr>        <list>    \n1         1 lm              regression    linear_reg   <spec[+]> \n2         2 gee             regression    linear_reg   <spec[+]> \n3         3 glm             regression    linear_reg   <spec[+]> \n```\n:::\n:::\n\n\nAs shown we can easily select the models we want either by choosing the supported parsnip function like linear_reg() or by choose the desired engine, you can also use them both in conjunction with each other!\n\nNow, what if you want to create a non-tuning model spec without using the fast_regression_parsnip_spec_tbl() function. Well, you can. The function is called create_model_spec().\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncreate_model_spec(\n .parsnip_eng = list(\"lm\",\"glm\",\"glmnet\",\"cubist\"),\n .parsnip_fns = list(\n      rep(\n        \"linear_reg\", 3),\n        \"cubist_rules\"\n     )\n )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 4\n  .parsnip_engine .parsnip_mode .parsnip_fns .model_spec\n  <chr>           <chr>         <chr>        <list>     \n1 lm              regression    linear_reg   <spec[+]>  \n2 glm             regression    linear_reg   <spec[+]>  \n3 glmnet          regression    linear_reg   <spec[+]>  \n4 cubist          regression    cubist_rules <spec[+]>  \n```\n:::\n\n```{.r .cell-code}\ncreate_model_spec(\n .parsnip_eng = list(\"lm\",\"glm\",\"glmnet\",\"cubist\"),\n .parsnip_fns = list(\n      rep(\n        \"linear_reg\", 3),\n        \"cubist_rules\"\n     ),\n .return_tibble = FALSE\n )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$.parsnip_engine\n$.parsnip_engine[[1]]\n[1] \"lm\"\n\n$.parsnip_engine[[2]]\n[1] \"glm\"\n\n$.parsnip_engine[[3]]\n[1] \"glmnet\"\n\n$.parsnip_engine[[4]]\n[1] \"cubist\"\n\n\n$.parsnip_mode\n$.parsnip_mode[[1]]\n[1] \"regression\"\n\n\n$.parsnip_fns\n$.parsnip_fns[[1]]\n[1] \"linear_reg\"\n\n$.parsnip_fns[[2]]\n[1] \"linear_reg\"\n\n$.parsnip_fns[[3]]\n[1] \"linear_reg\"\n\n$.parsnip_fns[[4]]\n[1] \"cubist_rules\"\n\n\n$.model_spec\n$.model_spec[[1]]\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n$.model_spec[[2]]\nLinear Regression Model Specification (regression)\n\nComputational engine: glm \n\n\n$.model_spec[[3]]\nLinear Regression Model Specification (regression)\n\nComputational engine: glmnet \n\n\n$.model_spec[[4]]\nCubist Model Specification (regression)\n\nComputational engine: cubist \n```\n:::\n:::\n\n\nNow the reason we are here. Let’s take a look at the first function for modeling with tidyAML, fast_regression().\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(recipes)\nlibrary(dplyr)\nlibrary(purrr)\n\nrec_obj <- recipe(mpg ~ ., data = mtcars)\nfrt_tbl <- fast_regression(\n  .data = mtcars, \n  .rec_obj = rec_obj, \n  .parsnip_eng = c(\"lm\",\"glm\"),\n  .parsnip_fns = \"linear_reg\"\n)\n\nglimpse(frt_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 2\nColumns: 8\n$ .model_id       <int> 1, 2\n$ .parsnip_engine <chr> \"lm\", \"glm\"\n$ .parsnip_mode   <chr> \"regression\", \"regression\"\n$ .parsnip_fns    <chr> \"linear_reg\", \"linear_reg\"\n$ model_spec      <list> [~NULL, ~NULL, NULL, regression, TRUE, NULL, lm, TRUE]…\n$ wflw            <list> [cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb, mp…\n$ fitted_wflw     <list> [cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb, mp…\n$ pred_wflw       <list> [<tbl_df[24 x 1]>], [<tbl_df[24 x 1]>]\n```\n:::\n:::\n\n\nNow lets take a look at a few different things in the `frt_tbl`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(frt_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \".model_id\"       \".parsnip_engine\" \".parsnip_mode\"   \".parsnip_fns\"   \n[5] \"model_spec\"      \"wflw\"            \"fitted_wflw\"     \"pred_wflw\"      \n```\n:::\n:::\n\n\nLet's look at a single model spec.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrt_tbl %>% slice(1) %>% select(model_spec) %>% pull() %>% pluck(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n:::\n:::\n\n\nNow the `wflw` column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrt_tbl %>% slice(1) %>% select(wflw) %>% pull() %>% pluck(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n:::\n:::\n\n\nThe fitted wflw object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrt_tbl %>% slice(1) %>% select(fitted_wflw) %>% pull() %>% pluck(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)          cyl         disp           hp         drat           wt  \n   11.77621      0.59296      0.01626     -0.03191     -0.55350     -5.30785  \n       qsec           vs           am         gear         carb  \n    0.97840      2.64023      1.68549      0.87059      0.58785  \n```\n:::\n\n```{.r .cell-code}\nfrt_tbl %>% slice(1) %>% select(fitted_wflw) %>% pull() %>% pluck(1) %>%\n  broom::glance() %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1\nColumns: 12\n$ r.squared     <dbl> 0.9085669\n$ adj.r.squared <dbl> 0.8382337\n$ sigma         <dbl> 2.337527\n$ statistic     <dbl> 12.91804\n$ p.value       <dbl> 3.367361e-05\n$ df            <dbl> 10\n$ logLik        <dbl> -47.07551\n$ AIC           <dbl> 118.151\n$ BIC           <dbl> 132.2877\n$ deviance      <dbl> 71.03241\n$ df.residual   <int> 13\n$ nobs          <int> 24\n```\n:::\n:::\n\n\nAnd finally the predictions (this one I am probably going to change up).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrt_tbl %>% slice(1) %>% select(pred_wflw) %>% pull() %>% pluck(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 24 × 1\n   .pred\n   <dbl>\n 1  17.4\n 2  28.4\n 3  17.2\n 4  10.7\n 5  13.4\n 6  17.0\n 7  22.8\n 8  14.3\n 9  22.4\n10  15.5\n# … with 14 more rows\n```\n:::\n:::\n\n\nVoila!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}