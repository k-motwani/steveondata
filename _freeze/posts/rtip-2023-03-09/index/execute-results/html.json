{
  "hash": "e36ee18a82fede3c0cdb17722a3174b1",
  "result": {
    "markdown": "---\ntitle: \"Multiple Solutions to speedup tidy_bernoulli() with {data.table}\"\nauthor: \"Steven P. Sanderson II, MPH\"\ndate: \"2023-03-09\"\ncategories: [code, rtip, tidydensity, data.table]\n---\n\n\n# Introduction\n\nI had just recently posted on making an attempt to speedup computations with my\npackage [`{TidyDensity}`](https://www.spsanderson.com/TidyDensity/) using a purely\ndata.table solution, yes of course I can use `{dtplyr}` or `{tidytable}` but that \nnot the challenge put to me.\n\nMy original attempt was worse than the original solution of `tidy_bernoulli()`. \nAfter I posted on Mastadon, LinkedIn and Reddit, I recieved potential solutions\nfrom each site by users. Let's check them out below.\n\n# Function\n\nFirst let's load in the necessary libraries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(rbenchmark)\nlibrary(TidyDensity)\n```\n:::\n\n\nNow let's look at the different solutions.\n\n::: {.cell}\n\n```{.r .cell-code}\n# My original new function\nnew_func <- function(num_sims, n, pr) {\n\n  # Create a data.table with one row per simulation\n  sim_data <- data.table(sim_number = factor(seq(1, num_sims, 1)))\n\n  # Group the data by sim_number and add columns for x and y\n  sim_data[, `:=` (\n    x = list(1:n),\n    y = list(stats::rbinom(n = n, size = 1, prob = pr))\n  ), by = sim_number]\n\n  # Compute the density of the y values and add columns for dx and dy\n  sim_data[, `:=` (\n    d = list(density(unlist(y), n = n)[c(\"x\", \"y\")] |>\n               set_names(\"dx\", \"dy\") |>\n               as_tibble())\n  ), by = sim_number]\n\n  # Compute the p-values for the y values and add a column for p\n  sim_data[, `:=` (\n    p = list(stats::pbinom(unlist(y), size = 1, prob = pr))\n  ), by = sim_number]\n\n  # Compute the q-values for the p-values and add a column for q\n  sim_data[, `:=` (\n    q = list(stats::qbinom(unlist(p), size = 1, prob = pr))\n  ), by = sim_number]\n\n  # Unnest the columns for x, y, d, p, and q\n  sim_data <- sim_data[,\n                       unnest(\n                         .SD,\n                         cols = c(\"x\", \"y\", \"d\", \"p\", \"q\")\n                       ),\n                       by = sim_number]\n\n  # Remove the grouping\n  sim_data[, sim_number := as.factor(sim_number)]\n\n  return(sim_data)\n}\n\nreddit_func <- function(num_sims, n, pr) {\n  sim_dat <- data.table(sim_number = rep(1:num_sims,each=n),\n                        x          = rep(1:n,num_sims))\n\n  sim_dat[, y := stats::rbinom(n = n, size = 1, prob = pr), by=sim_number]\n  sim_dat[, c(\"dx\",\"dy\") := density(y,n=n)[c(\"x\",\"y\")]    , by=sim_number]\n  sim_dat[, p := stats::pbinom(y, size = 1, prob = pr)    , by=sim_number]\n  sim_dat[, q := stats::qbinom(p, size = 1, prob = pr)    , by=sim_number]\n  \n  return(sim_dat)\n}\n\nmastadon_func <- function(num_sims, n, pr){\n  sim_data <- data.table(sim_number = 1:num_sims\n  )[, `:=`( x = .(1:n), y= .(rbinom(n = n, size = 1, prob = pr))), sim_number\n  ][, `:=`( d = .(density(unlist(y), n = n)[c('x','y')] |> \n                    as.data.table() |> \n                    setnames(c('dx','dy'))\n                  )\n            ), sim_number\n  ][, `:=`( p = .(pbinom(unlist(y), size = 1, prob = pr))), sim_number\n  ][, `:=`( q = .(qbinom(unlist(p), size = 1, prob = pr))), sim_number]\n\n    cbind(\n      sim_data[, lapply(.SD, unlist), by = sim_number, .SDcol = c('x','y','p','q')],\n      rbindlist(sim_data$d)\n    ) |>\n    setcolorder(c('sim_number','x','y','dx','dy'))\n    \n    return(sim_data)\n}\n\nlinkedin_func <- function(num_sims, n, pr) {\n\n  # Create a data.table with one row per simulation\n  sim_data <- CJ(sim_number = factor(1:num_sims), x = 1:n)\n\n  # Group the data by sim_number and add columns for x and y\n  sim_data[, y := stats::rbinom(n = .N, size = 1, prob = pr)]\n\n\n  # Compute the density of the y values and add columns for dx and dy\n  sim_data[, c(\"dx\", \"dy\") := density(y, n = n)[c(\"x\", \"y\")], by = sim_number]\n\n  # Compute the p-values for the y values and add a column for p\n  sim_data[, p := stats::pbinom(y, size = 1, prob = pr)]\n\n  # Compute the q-values for the p-values and add a column for q\n  sim_data[, q := stats::qbinom(p, size = 1, prob = pr)]\n  setkey(sim_data, NULL) # needed only to compare with new_func\n  return(sim_data)\n}\n```\n:::\n\n\nAll of the functions work in the same set of three arguments as input:\n*  `num_sims`: an integer value that specifies the number of simulations to run\n*  `n`: an integer value that specifies the sample size\n*  `pr`: a numeric value that specifies the probability of success\n\nThe functions use the `data.table` package to create a data table named sim_dat/sim_data. The data table has two columns: sim_number and x. The sim_number column represents the simulation number, and x column represents the observation number.\n\nThe functions then generate random binary data using the `rbinom` function from the `stats` package. The function generates n binary data points for each simulation number (sim_number) using the input parameter pr as the probability of success. The resulting binary data points are stored in the y column of sim_dat/data.\n\nNext, the function calculates the density of y using the density function from the stats package. The function calculates the density separately for each simulation number (sim_number) and stores the resulting values in the dx and dy columns of sim_dat/data.\n\nThe functions then calculate the cumulative probability (p) of each binary data point using the pbinom function from the stats package. The function calculates the cumulative probability separately for each simulation number (sim_number) and stores the resulting values in the p column of sim_dat.\n\nFinally, the functions calculate the inverse of the cumulative probability (q) using the qbinom function from the stats package. The function calculates the inverse of the cumulative probability separately for each simulation number (sim_number) and stores the resulting values in the q column of sim_dat.\n\nThe functions then return the data table containing the results of the simulations.\n\n# Example\n\nHow do they stack up to each other? Lets see!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 50\npr <- 0.1\nnum_sims <- sims <- 5\n\nbenchmark(\n  \"tidy_bernoulli()\" = {\n    tidy_bernoulli(.n = n, .prob = pr, .num_sims = sims)\n  },\n  \"my.first.attempt\" = {\n    new_func(n = n, pr = pr, num_sims = sims)\n  },\n  \"linkedin.attempt\" = {\n    linkedin_func(n = n, pr = pr, num_sims = sims)\n  },\n  \"mastadon.attempt\" = {\n    mastadon_func(n = n, pr = pr, num_sims = sims)\n  },\n  \"reddit.attempt\" = {\n    reddit_func(n = n, pr = pr, num_sims = sims)\n  },\n  replications = 200,\n  columns = c(\"test\",\"replications\",\"elapsed\",\"relative\",\"user.self\",\"sys.self\"  )\n) |>\n  arrange(relative)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              test replications elapsed relative user.self sys.self\n1 linkedin.attempt          200    0.84    1.000      0.64     0.00\n2   reddit.attempt          200    0.86    1.024      0.69     0.03\n3 mastadon.attempt          200    1.57    1.869      1.17     0.08\n4 tidy_bernoulli()          200    6.47    7.702      4.68     0.11\n5 my.first.attempt          200    8.82   10.500      6.67     0.01\n```\n:::\n:::\n\n\nVoila!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}