{
  "hash": "5de754d7ecb29c1000e0bfedfee47639",
  "result": {
    "markdown": "---\ntitle: \"How fast does a compressed file in?\"\nauthor: \"Steven P. Sanderson II, MPH\"\ndate: \"2023-03-27\"\ncategories: [rtip, benchmark]\n---\n\n\n# Introduction\n\nI received an email over the weekend in regards to my last post not containing the reading in of `gz` compressed file(s) for the benchmarking. While this was not an over site per-se it was a good reminder that people would probably be interested in seeing this as well.\n\nBenchmarking is the process of measuring and comparing the performance of different programs, tools, or configurations in order to identify which one is the most efficient for a specific task. It is a critical step in software development that can help developers identify performance bottlenecks and improve the overall performance of their applications.\n\nIn this post I create a square matrix and then convert it to a data.frame (2,000 rows by 2,000 columns) and then saved it as a gz compressed csv file. The benchmark compares different R packages and functions, including base `R`, `data.table`, `vroom`, and `readr`, and measures their relative speeds based on the time it takes to read in the `.csv.gz` file.\n\nHere are some pro's of trying things different ways and properly benchmarking them:\n\n*    Identify the most efficient solution: Benchmarking can help you identify the most efficient solution for a specific task. By measuring the relative speeds of different programs or tools, you can determine which one is the fastest and use it to improve the performance of your application.\n\n*    Optimize resource utilization: Benchmarking can help you optimize resource utilization by identifying programs or tools that consume more resources than others. By choosing the most resource-efficient solution, you can reduce the cost of running your application and improve its scalability.\n\n*    Avoid premature optimization: Benchmarking can help you avoid premature optimization by measuring the performance of different programs or tools before you start optimizing them. By identifying the slowest parts of your application, you can focus your optimization efforts on the most critical areas and avoid wasting time optimizing code that doesn't need it.\n\n*    Keep up with technology: Benchmarking can help you keep up with technology by comparing the performance of different tools and libraries. By staying up to date with the latest technologies, you can improve the performance of your application and stay ahead of your competitors.\n\n*    Improve code quality: Benchmarking can help you improve the quality of your code by identifying performance bottlenecks and areas for optimization. By optimizing your code, you can improve its maintainability, reliability, and readability.\n\nIn conclusion, benchmarking is an essential tool for software developers that can help them identify the most efficient solutions for their applications. By measuring the relative speeds of different programs or tools, developers can optimize resource utilization, avoid premature optimization, keep up with technology, and improve the quality of their code.\n\n# Function\n\nThe different functions I use in the benchmarking are as follows:\n\n## Base R\n*  `read.csv()`\n*  `read.table()`\n\n## data.table\n*  `fread`\n\n## vroom\n*  `vroom()` with altrep = FALSE\n*  `vroom()` with altrep = TRUE\n\n## readr\n*  `read_csv()`\n\n# Example\n\nLet's make a 2,000 by 2,000 matrix, covert to a `data.frame` and then save it out as a `.csv` file and then convert to a `.gz` file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(R.utils)\n\n# create a 1000 x 1000 matrix of random numbers\nmy_matrix <- matrix(rnorm(2000000), nrow = 2000, ncol = 2000) |>\n  as.data.frame()\n\n# Make and save gzipped file\nwrite.csv(my_matrix, \"my_matrix.csv\")\ngzip(filename = \"my_matrix.csv\", destname = \"matrix.csv.gz\",\n     overwrite = FALSE, remove = TRUE)\n```\n:::\n\n\nOk now that the data is written we can benchmark the read in times from various packages.\n\n## Benchmarking\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rbenchmark)\nlibrary(data.table)\nlibrary(readr)\nlibrary(vroom)\nlibrary(dplyr)\n\nn <- 30\n\nbenchmark(\n  # Base R\n  \"read.table\" = {\n    a <- read.table(\"matrix.csv.gz\", sep = \",\")\n  },\n  \"read.csv\" = {\n    b <- read.csv(\"matrix.csv.gz\", sep = \",\")\n  },\n  \n  # data.table\n  \"fread\" = {\n    c <- fread(\"matrix.csv.gz\", sep = \",\")\n  },\n  \n  # vroom\n  \"vroom alltrep false\" = {\n    d <- vroom(\"matrix.csv.gz\", delim = \",\")\n  },\n  \"vroom alltrep true\" = {\n    e <- vroom(\"matrix.csv.gz\", delim = \",\", altrep = TRUE)\n  },\n  \n  # readr\n  \"readr\" = {\n    f <- read_csv(\"matrix.csv.gz\")\n  },\n  \n  # Replications\n  replications = n,\n  \n  # Columns\n  columns = c(\n    \"test\",\"replications\",\"elapsed\",\"relative\",\"user.self\",\"sys.self\")\n) |>\n  arrange(relative)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 test replications elapsed relative user.self sys.self\n1               fread           30   19.44    1.000     13.56     1.59\n2  vroom alltrep true           30   22.06    1.135     10.54     2.63\n3 vroom alltrep false           30   24.75    1.273     10.22     2.84\n4          read.table           30   94.34    4.853     79.02     0.64\n5            read.csv           30  143.28    7.370    115.64     0.74\n6               readr           30  177.61    9.136     50.37    10.05\n```\n:::\n:::\n\n\nVoila!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}