{
  "hash": "183f395ff63926026b9dbbd16cb9fbdf",
  "result": {
    "markdown": "---\ntitle: \"Building models with {shiny} and {tidyAML} Part 3\"\nauthor: \"Steven P. Sanderson II, MPH\"\ndate: \"2023-04-27\"\ncategories: [rtip, shiny, tidymodels, tidyaml]\n---\n\n\n# Introduction\n\nAs data science continues to be a sought-after field, creating a reliable and accurate model is essential. While there are various machine learning algorithms available, the process of selecting the correct algorithm can be complex. The [`{tidyAML}`](https://www.spsanderson.com/tidyAML/) package, part of the `tidymodels` suite, offers an easy-to-use, consistent interface for building machine learning models. In this post, we will explore a Shiny application that utilizes `tidyAML` to build a machine learning model.\n\nToday I have updated the `tidyAML` shiny app to include the ability to set the parameter of the `fast_regression()` function `.parsnip_fns` and this is things like `linear_reg`. \n\nHere is a full list of what is available:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyAML)\nlibrary(dplyr)\n\nc(\"all\",\n  make_regression_base_tbl() |> \n    pull(.parsnip_fns) |> \n    unique()\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"all\"              \"linear_reg\"       \"cubist_rules\"     \"poisson_reg\"     \n [5] \"bag_mars\"         \"bag_tree\"         \"bart\"             \"boost_tree\"      \n [9] \"decision_tree\"    \"gen_additive_mod\" \"mars\"             \"mlp\"             \n[13] \"nearest_neighbor\" \"rand_forest\"      \"rule_fit\"         \"svm_linear\"      \n[17] \"svm_poly\"         \"svm_rbf\"         \n```\n:::\n:::\n\n\nI have updated the UI to reflect using that method as well. Here is the UI changes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n      selectInput(\"model_engine\", \"Select a model engine:\", \n                  choices = c(\"all\",\n                              make_regression_base_tbl() |> \n                                pull(.parsnip_engine) |> \n                                unique()\n                  )\n      ),\n      selectInput(\"model_fns\", \"Select a model function:\",\n                  choices = c(\"all\",\n                              make_regression_base_tbl() |> \n                                pull(.parsnip_fns) |> \n                                unique()\n                              )\n```\n:::\n\n\nHere are some pictures showing the changes:\n\n![UI Change](1.PNG)\n\n![UI Change 2](2.PNG)\n\n![Output](3.PNG)\n\nSo what this means is that we can just pick a function like `parsnip::linear_reg()` and leave the __engine__ set to `\"all\"` and it will build models for all engines supported that work with `linear_reg()`.\n\n# The Shiny Application\n\nThe Shiny application is a graphical user interface (GUI) that allows users to select a dataset, predictor column, model type, and engine, and then build a machine learning model. The user can upload a CSV or TXT file or choose one of two built-in datasets: \"mtcars\" or \"iris\". The user can select the predictor column, which is the variable used to predict the outcome, and then choose the model type, either \"regression\" or \"classification\". Next, the user can select a model engine and a model function to use in building the model. Once the user has made all the selections, they can click the \"Build Model\" button to create the model.\n\nThe code for the Shiny application can be broken down into two parts, the User Interface (UI) and the Server. Let's take a closer look at each of these parts.\n\n# The UI\n\nThe UI is created using the `fluidPage()` function from the shiny package. The `titlePanel()` function creates the title of the application. The `sidebarLayout()` function creates the sidebar and main panel. The sidebar contains input controls such as file input, select input, and an action button. The main panel displays the outputs generated by the model.\n\nThe `fileInput()` function creates a widget that allows the user to upload a data file. The `selectInput()` function creates dropdown menus for the user to select the dataset, predictor column, model type, model engine, and model function. The `actionButton()` function creates a button that the user clicks to build the model. The `verbatimTextOutput()` function and `reactableOutput()` function display the output generated by the model.\n\n# The Server\n\nThe Server is where the input data is processed, the model is built, and the output is generated. The Server is created using the server() function from the shiny package.\n\nThe `reactive()` function is used to create a reactive object called data that reads in the data file or built-in dataset selected by the user. The `eventReactive()` function is used to create a reactive object called recipe_obj that creates a recipe for preprocessing the data. The recipe includes steps to normalize the numeric variables and remove the outcome variable from the recipe.\n\nTwo other reactive objects, model_engine and model_fns, are created using the switch() function. These objects contain a list of available engines and model functions for the user to choose from.\n\nFinally, the `eventReactive()` function is used to create a reactive object called model that builds the machine learning model. The `fast_regression()` and `fast_classification()` functions from the tidyAML package are used to build the regression and classification models, respectively.\n\n# Conclusion\n\nIn this post, we explored a Shiny application that uses tidyAML to build a machine learning model. The application allows users to select a dataset, predictor column, model type, engine, and function to build a machine learning model. The Shiny application is an excellent tool for those who are new to machine learning or those who want to streamline the rapid prototyping process.\n\n# Full Application\n\nThis is a work in progress, and I want you to steal this code and see what you can come up with!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(shiny)\nlibrary(tidyAML)\nlibrary(recipes)\nlibrary(DT)\nlibrary(glmnet)\nlibrary(rules)\nlibrary(tidymodels)\nlibrary(reactable)\n\ntidymodels_prefer()\n\nui <- fluidPage(\n  titlePanel(\"tidyAML Model Builder\"),\n  sidebarLayout(\n    sidebarPanel(\n      fileInput(\"file\", \"Upload your data file (csv or txt):\"),\n      selectInput(\"dataset\", \n                  \"Choose a built-in dataset:\", \n                  choices = c(\"mtcars\", \"iris\")\n      ),\n      selectInput(\"predictor_col\", \n                  \"Select the predictor column:\", \n                  choices = NULL\n      ),\n      selectInput(\"model_type\", \n                  \"Select a model type:\", \n                  choices = c(\"regression\", \"classification\")),\n      selectInput(\"model_engine\", \"Select a model engine:\", \n                  choices = c(\"all\",\n                              make_regression_base_tbl() |> \n                                pull(.parsnip_engine) |> \n                                unique()\n                  )\n      ),\n      selectInput(\"model_fns\", \"Select a model function:\",\n                  choices = c(\"all\",\n                              make_regression_base_tbl() |> \n                                pull(.parsnip_fns) |> \n                                unique()\n                              )\n      ),\n      actionButton(\"build_model\", \"Build Model\"),\n      verbatimTextOutput(\"recipe_output\")\n    ),\n    mainPanel(\n      verbatimTextOutput(\"model_table\"),\n      reactableOutput(\"model_reactable\")\n    )\n  )\n)\n\nserver <- function(input, output, session) {\n  \n  data <- reactive({\n    if (!is.null(input$file)) {\n      df <- read.csv(\n        input$file$datapath, \n        header = TRUE, \n        stringsAsFactors = FALSE\n      )\n      updateSelectInput(\n        session, \n        \"predictor_col\", \n        choices = names(df)\n      )\n      return(df)\n    } else if (!is.null(input$dataset)) {\n      df <- get(input$dataset)\n      updateSelectInput(\n        session, \n        \"predictor_col\", \n        choices = names(df)\n      )\n      return(df)\n    }\n  })\n  \n  recipe_obj <- eventReactive(input$predictor_col, {\n    rec <- recipe(as.formula(paste(input$predictor_col, \"~ .\")), \n                  data = data()\n    ) |>\n      step_normalize(all_numeric(), -all_outcomes())\n    return(rec)\n  })\n  \n  model_engine <- reactive({\n    switch(input$model_engine,\n           \"all\" = \"all\",\n           \"lm\" = \"lm\",\n           \"brulee\" = \"brulee\",\n           \"gee\" = \"gee\",\n           \"glm\" = \"glm\",\n           \"glmer\" = \"glmer\",\n           \"glmnet\" = \"glmnet\",\n           \"gls\" = \"gls\",\n           \"lme\" = \"lme\",\n           \"lmer\" = \"lmer\",\n           \"stan\" = \"stan\",\n           \"stan_glmer\" = \"stan_glmer\",\n           \"Cubist\" = \"Cubist\",\n           \"hurdle\" = \"hurdle\",\n           \"zeroinfl\" = \"zeroinfl\",\n           \"earth\" = \"earth\",\n           \"rpart\" = \"rpart\",\n           \"dbarts\" = \"dbarts\",\n           \"xgboost\" = \"xgboost\"          ,\n           \"lightgbm\" = \"lightgbm\",\n           \"partykit\" = \"partykit\",\n           \"mgcv\" = \"mgcv\",\n           \"nnet\" = \"nnet\",\n           \"kknn\" = \"kknn\",\n           \"ranger\" = \"ranger\",\n           \"randomForest\" = \"randomForest\",\n           \"xrf\" = \"xrf\",\n           \"LiblineaR\" = \"LiblineaR\",\n           \"kernlab = kernlab\")\n  })\n  \n  model_fns <- reactive({\n    switch(input$model_fns,\n           \"all\" = \"all\",\n           \"linear_reg\" = \"linear_reg\",\n           \"cubist_rules\" = \"cubist_rules\",\n           \"poisson_reg\" = \"poisson_reg\",\n           \"bag_mars\" = \"bag_mars\",\n           \"bag_tree\" = \"bag_tree\",\n           \"bart\" = \"bart\",\n           \"boost_tree\" = \"boost_tree\",\n           \"decision_tree\" = \"decision_tree\",\n           \"gen_additive_mod\" = \"gen_additive_mod\",\n           \"mars\" = \"mars\",\n           \"mlp\" = \"mlp\",\n           \"nearest_neighbor\" = \"nearest_neighbor\",\n           \"rand_forest\" = \"rand_forest\",\n           \"rule_fit\" = \"rule_fit\",\n           \"svm_linear\" = \"svm_linear\",\n           \"svm_poly\" = \"svm_poly\",\n           \"svm_rbf\" = \"svm_rbf\"\n    )\n  })\n  \n  model <- eventReactive(input$build_model, {\n    if (input$model_type == \"regression\") {\n      mod <- fast_regression(.data = data(),\n                             .rec_obj = recipe_obj(),\n                             .parsnip_eng = model_engine(),\n                             .parsnip_fns = model_fns())\n    } else if (input$model_type == \"classification\") {\n      mod <- fast_classification(.data = data(),\n                                 .rec_obj = recipe_obj(),\n                                 .parsnip_eng = model_engine(),\n                                 .parsnip_fns = model_fns())\n    }\n    return(mod)\n  })\n  \n  output$recipe_output <- renderPrint({\n    if (!is.null(input$predictor_col)) {\n      summary(recipe_obj())\n    }\n  })\n  \n  output$model_table <- renderPrint({\n    if (input$build_model > 0) {\n      print(model())\n    }\n  })\n  \n  output$model_reactable <- renderReactable({\n    if (input$build_model > 0) {\n      reactable(model())\n    }\n  })\n  \n}\n\nshinyApp(ui = ui, server = server)\n```\n:::\n\n\nVoila!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}